/**
 * OpenAI GPT-5 Family Tools
 * Released August 7, 2025
 * Special API requirements: No custom temperature, uses verbosity parameter
 */

import { z } from "zod";
import { config } from "dotenv";
import * as path from 'path';
import { fileURLToPath } from 'url';
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
config({ path: path.resolve(__dirname, '../../../.env') });

// OpenAI API configuration
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const OPENAI_API_URL = "https://api.openai.com/v1/chat/completions";

// Feature flag for GPT-5 models (disable until OpenAI fixes issues)
// Set ENABLE_GPT5=true in .env to enable GPT-5 models
const GPT5_ENABLED = process.env.ENABLE_GPT5 === 'true';

if (!GPT5_ENABLED) {
  console.warn('‚ö†Ô∏è GPT-5 models are DISABLED (invisible token issues). Set ENABLE_GPT5=true to enable.');
}

// GPT-5 family models with pricing (August 2025)
export enum GPT5Model {
  GPT5 = "gpt-5",           // $1.25/$10 per M tokens - Most advanced
  GPT5_MINI = "gpt-5-mini", // $0.25/$2 per M tokens - Best value
  GPT5_NANO = "gpt-5-nano"  // $0.05/$0.40 per M tokens - Ultra low-cost
}

// Model capabilities and pricing
export const GPT5_MODEL_INFO = {
  [GPT5Model.GPT5]: {
    inputPrice: 1.25,
    outputPrice: 10.00,
    contextWindow: 1000000,
    features: ["best-reasoning", "verbosity", "invisible-reasoning-tokens", "tools"],
    benchmarks: {
      AIME2025: 94.6,
      SWEBench: 74.9,
      errorRate: 1.6,
      deceptionRate: 2.1
    },
    description: "Most advanced reasoning, lowest error rate"
  },
  [GPT5Model.GPT5_MINI]: {
    inputPrice: 0.25,
    outputPrice: 2.00,
    contextWindow: 1000000,
    features: ["good-reasoning", "verbosity", "tools", "cost-efficient"],
    description: "80% cheaper output than GPT-5, great for most tasks"
  },
  [GPT5Model.GPT5_NANO]: {
    inputPrice: 0.05,
    outputPrice: 0.40,
    contextWindow: 128000,
    features: ["basic-reasoning", "fast", "ultra-low-cost"],
    description: "95% cheaper than GPT-5, for simple tasks"
  }
};

/**
 * Estimate token count (rough approximation)
 */
function estimateTokens(text: string): number {
  // Rough estimate: 1 token ‚âà 4 characters
  return Math.ceil(text.length / 4);
}

/**
 * Calculate estimated cost
 */
function calculateCost(
  model: GPT5Model,
  inputTokens: number,
  outputTokens: number
): { total: number; breakdown: string } {
  const info = GPT5_MODEL_INFO[model];
  const inputCost = (inputTokens * info.inputPrice) / 1000000;
  const outputCost = (outputTokens * info.outputPrice) / 1000000;
  const total = inputCost + outputCost;
  
  return {
    total,
    breakdown: `Input: $${inputCost.toFixed(4)} (${inputTokens} tokens) + Output: $${outputCost.toFixed(4)} (${outputTokens} tokens)`
  };
}

/**
 * Call OpenAI API for GPT-5 family models
 * Note: GPT-5 doesn't support custom temperature, only default (1.0)
 */
async function callGPT5(
  messages: Array<{ role: string; content: string }>,
  model: GPT5Model = GPT5Model.GPT5_MINI,
  verbosity: "low" | "medium" | "high" = "medium",
  maxTokens: number = 2048,
  reasoningEffort: "minimal" | "low" | "medium" | "high" = "minimal"
): Promise<{ response: string; usage?: any; finishReason?: string }> {
  if (!OPENAI_API_KEY) {
    return { 
      response: `[OpenAI API key not configured. Add OPENAI_API_KEY to .env file]` 
    };
  }
  
  if (!GPT5_ENABLED) {
    return {
      response: `[GPT-5 models are disabled due to invisible token issues. Set ENABLE_GPT5=true in .env to enable. Using GPT-4.1-mini instead would be 6x cheaper and more reliable.]`
    };
  }

  // Fallback chain for GPT-5 models
  const modelFallbacks: Record<string, string[]> = {
    [GPT5Model.GPT5]: [GPT5Model.GPT5_MINI, "gpt-4.1-mini", "gpt-4o"],
    [GPT5Model.GPT5_MINI]: [GPT5Model.GPT5_NANO, "gpt-4.1-mini"],
    [GPT5Model.GPT5_NANO]: ["gpt-4.1-mini", "gpt-4o-mini"]
  };

  const modelsToTry = [model, ...(modelFallbacks[model] || [])];
  let lastError: string = '';

  for (const currentModel of modelsToTry) {
    try {
      // GPT-5 specific parameters
      const isGPT5 = currentModel.startsWith("gpt-5");
      const requestBody: any = {
        model: currentModel,
        messages,
        stream: false
      };
      
      // GPT-5 models use max_completion_tokens, others use max_tokens
      if (isGPT5) {
        requestBody.max_completion_tokens = maxTokens;
      } else {
        requestBody.max_tokens = maxTokens;
      }
      
      // GPT-5 models: use verbosity and reasoning_effort
      if (isGPT5) {
        requestBody.verbosity = verbosity;
        requestBody.reasoning_effort = reasoningEffort;
        // Don't set temperature for GPT-5 - let it use defaults
        // requestBody.temperature = 1.0;
      } else {
        // Fallback to GPT-4 models: use temperature
        requestBody.temperature = 0.7;
      }

      const response = await fetch(OPENAI_API_URL, {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        const error = await response.text();
        lastError = `${currentModel}: ${response.statusText} - ${error}`;
        
        // Check for specific errors
        if (error.includes("temperature") && error.includes("does not support")) {
          console.log(`Model ${currentModel} doesn't support custom temperature, retrying with default...`);
          // Retry without temperature
          delete requestBody.temperature;
          const retryResponse = await fetch(OPENAI_API_URL, {
            method: "POST",
            headers: {
              "Authorization": `Bearer ${OPENAI_API_KEY}`,
              "Content-Type": "application/json"
            },
            body: JSON.stringify(requestBody)
          });
          
          if (retryResponse.ok) {
            const data = await retryResponse.json();
            return {
              response: data.choices?.[0]?.message?.content || "No response",
              usage: data.usage
            };
          }
        }
        
        if (response.status === 404 || error.includes('model') || error.includes('not found')) {
          console.log(`Model ${currentModel} not available, trying fallback...`);
          continue;
        }
        throw new Error(lastError);
      }

      const data = await response.json();
      const result = data.choices?.[0]?.message?.content || "No response from OpenAI";
      const finishReason = data.choices?.[0]?.finish_reason;
      
      // Check if response was truncated
      if (finishReason === "length") {
        console.warn(`Warning: Response truncated due to max_tokens limit (${maxTokens}). Consider increasing max_tokens.`);
      }
      
      if (currentModel !== model) {
        return {
          response: `[Using ${currentModel} (${model} not available)]\n\n${result}`,
          usage: data.usage,
          finishReason
        };
      }
      
      return {
        response: result,
        usage: data.usage,
        finishReason
      };
      
    } catch (error) {
      lastError = `${currentModel}: ${error instanceof Error ? error.message : String(error)}`;
      continue;
    }
  }
  
  return { 
    response: `[OpenAI error - all models failed: ${lastError}]` 
  };
}

/**
 * GPT-5 Reasoning Tool - Most advanced with cost confirmation
 */
export const gpt5ReasonTool = {
  name: "gpt5_reason",
  description: "GPT-5: Most advanced reasoning ($1.25/$10 per M tokens) - REQUIRES CONFIRMATION",
  parameters: z.object({
    query: z.string().describe("Complex problem requiring deep reasoning"),
    context: z.string().optional().describe("Additional context"),
    verbosity: z.enum(["low", "medium", "high"]).optional().default("medium")
      .describe("WARNING: 'high' verbosity increases invisible token usage"),
    maxTokens: z.number().optional().default(4000)
      .describe("OpenAI recommends 25000+ for GPT-5, but that's expensive. 4000 minimum."),
    reasoningEffort: z.enum(["minimal", "low", "medium", "high"]).optional().default("minimal")
      .describe("Use 'minimal' to avoid invisible token costs. 'high' often returns empty!"),
    estimatedOutputTokens: z.number().optional().default(2000)
      .describe("Estimated output tokens for cost calculation"),
    confirmUsage: z.boolean().optional().default(false)
      .describe("Confirm expensive GPT-5 usage")
  }),
  execute: async (args: any, { log }: any) => {
    // Calculate estimated cost
    const inputTokens = estimateTokens(args.query + (args.context || ''));
    const outputTokens = args.estimatedOutputTokens;
    const cost = calculateCost(GPT5Model.GPT5, inputTokens, outputTokens);
    
    // Require confirmation for GPT-5
    if (!args.confirmUsage) {
      return `‚ö†Ô∏è GPT-5 Usage Confirmation Required

Model: GPT-5 (Most advanced reasoning)
Pricing: $1.25 per M input tokens, $10 per M output tokens
Estimated visible tokens: ~${inputTokens} input, ~${outputTokens} output
Estimated visible cost: $${cost.total.toFixed(4)}

‚ö†Ô∏è CRITICAL WARNINGS:
‚Ä¢ GPT-5 uses INVISIBLE reasoning tokens (billed at $10/M)
‚Ä¢ Can use 30-100x more tokens than shown (real cost 30-100x higher)
‚Ä¢ OpenAI recommends 25,000+ tokens (would cost ~$0.25+ per call)
‚Ä¢ Dynamic routing makes behavior unpredictable
‚Ä¢ Often returns EMPTY responses with high reasoning_effort

Benchmarks:
‚Ä¢ AIME 2025 Math: 94.6% (best)
‚Ä¢ SWE-bench: 74.9% (best)
‚Ä¢ Error rate: 1.6% (lowest)

To proceed, set confirmUsage: true
STRONGLY RECOMMENDED: Use 'gpt41_mini' (100x cheaper, no invisible tokens)`;
    }
    
    const messages = [
      {
        role: "system",
        content: `You are GPT-5, the most advanced reasoning model.
Provide deep, step-by-step reasoning with clear explanations.
${args.context ? `Context: ${args.context}` : ''}`
      },
      {
        role: "user",
        content: args.query
      }
    ];
    
    // Force reasonable settings to avoid empty responses
    const safeVerbosity = args.verbosity === "high" ? "medium" : args.verbosity;
    // Force minimal reasoning to avoid massive invisible token costs
    const safeReasoningEffort = args.reasoningEffort === "high" || args.reasoningEffort === "medium" ? "low" : args.reasoningEffort;
    const result = await callGPT5(messages, GPT5Model.GPT5, safeVerbosity, args.maxTokens || 3000, safeReasoningEffort);
    
    if (result.usage) {
      const actualCost = calculateCost(
        GPT5Model.GPT5,
        result.usage.prompt_tokens,
        result.usage.completion_tokens
      );
      const truncatedWarning = result.finishReason === "length" ? "\n‚ö†Ô∏è Response was truncated. Increase maxTokens for full output." : "";
      return `${result.response}\n\n---\nüìä Usage: ${result.usage.total_tokens} tokens | Cost: $${actualCost.total.toFixed(4)}${truncatedWarning}`;
    }
    
    return result.response;
  }
};

/**
 * GPT-5-mini Tool - Cost-efficient, no confirmation needed
 */
export const gpt5MiniTool = {
  name: "gpt5_mini",
  description: "GPT-5-mini: 20-100x more expensive than GPT-4.1-mini due to invisible tokens ($0.25/$2 per M)",
  parameters: z.object({
    query: z.string().describe("Problem or task"),
    systemPrompt: z.string().optional().describe("System context"),
    verbosity: z.enum(["low", "medium", "high"]).optional().default("low")
      .describe("Keep 'low' to minimize invisible reasoning tokens"),
    maxTokens: z.number().optional().default(2000)
      .describe("Min 2000 recommended to avoid empty responses"),
    reasoningEffort: z.enum(["low", "medium", "high"]).optional().default("medium")
  }),
  execute: async (args: any, { log }: any) => {
    const messages = [
      ...(args.systemPrompt ? [{
        role: "system",
        content: args.systemPrompt
      }] : []),
      {
        role: "user",
        content: args.query
      }
    ];
    
    const result = await callGPT5(messages, GPT5Model.GPT5_MINI, args.verbosity, args.maxTokens, args.reasoningEffort);
    return result.response;
  }
};

/**
 * GPT-5-nano Tool - Ultra low-cost for simple tasks
 */
export const gpt5NanoTool = {
  name: "gpt5_nano",
  description: "GPT-5-nano: Ultra low-cost ($0.05/$0.40 per M tokens) for simple tasks",
  parameters: z.object({
    query: z.string().describe("Simple query or task"),
    maxTokens: z.number().optional().default(800)
      .describe("Max tokens for response")
  }),
  execute: async (args: any, { log }: any) => {
    const messages = [
      {
        role: "user",
        content: args.query
      }
    ];
    
    const result = await callGPT5(messages, GPT5Model.GPT5_NANO, "low", args.maxTokens, "minimal");
    return result.response;
  }
};

/**
 * Compare GPT-5 vs GPT-4 models
 */
export const compareGPT5vsGPT4Tool = {
  name: "compare_gpt5_vs_gpt4",
  description: "Compare GPT-5 models against GPT-4.1-mini for the same query",
  parameters: z.object({
    query: z.string().describe("Query to test"),
    includeGPT5: z.boolean().optional().default(false)
      .describe("Include expensive GPT-5 (requires confirmation)"),
    confirmGPT5: z.boolean().optional().default(false)
      .describe("Confirm GPT-5 usage if includeGPT5 is true")
  }),
  execute: async (args: any, { log }: any) => {
    const results: any = {};
    
    // Test GPT-5-mini (affordable)
    try {
      const startTime = Date.now();
      const gpt5MiniResult = await callGPT5(
        [{ role: "user", content: args.query }],
        GPT5Model.GPT5_MINI,
        "medium",
        1000,
        "minimal"
      );
      const duration = Date.now() - startTime;
      
      results["gpt-5-mini"] = {
        response: gpt5MiniResult.response.substring(0, 300) + '...',
        duration: `${duration}ms`,
        cost: "$0.00025 (estimated)",
        model: "GPT-5-mini"
      };
    } catch (error) {
      results["gpt-5-mini"] = { error: String(error) };
    }
    
    // Test GPT-5 if confirmed
    if (args.includeGPT5) {
      if (!args.confirmGPT5) {
        results["gpt-5"] = {
          status: "Skipped - requires confirmGPT5: true",
          estimatedCost: "$0.0125 for 1K tokens"
        };
      } else {
        try {
          const startTime = Date.now();
          const gpt5Result = await callGPT5(
            [{ role: "user", content: args.query }],
            GPT5Model.GPT5,
            "high",
            1500,
            "high"
          );
          const duration = Date.now() - startTime;
          
          results["gpt-5"] = {
            response: gpt5Result.response.substring(0, 300) + '...',
            duration: `${duration}ms`,
            cost: "$0.00125 (estimated)",
            model: "GPT-5"
          };
        } catch (error) {
          results["gpt-5"] = { error: String(error) };
        }
      }
    }
    
    // Test GPT-4.1-mini for comparison (using direct API call)
    try {
      const startTime = Date.now();
      const response = await fetch(OPENAI_API_URL, {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${OPENAI_API_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model: "gpt-4.1-mini",
          messages: [{ role: "user", content: args.query }],
          temperature: 0.7,
          max_completion_tokens: 500
        })
      });
      
      if (response.ok) {
        const data = await response.json();
        const duration = Date.now() - startTime;
        results["gpt-4.1-mini"] = {
          response: data.choices[0].message.content.substring(0, 300) + '...',
          duration: `${duration}ms`,
          cost: "$0.0004 (estimated)",
          model: "GPT-4.1-mini"
        };
      }
    } catch (error) {
      results["gpt-4.1-mini"] = { error: String(error) };
    }
    
    // Summary
    return `Model Comparison Results:
${JSON.stringify(results, null, 2)}

Cost Comparison (per 1K tokens):
‚Ä¢ GPT-5-nano: $0.00005 input + $0.0004 output
‚Ä¢ GPT-5-mini: $0.00025 input + $0.002 output
‚Ä¢ GPT-4.1-mini: $0.0004 input + $0.0001 output
‚Ä¢ GPT-5: $0.00125 input + $0.01 output

Recommendation: Use GPT-5-mini for most tasks (best balance)`;
  }
};

/**
 * Check if GPT-5 is available
 */
export function isGPT5Available(): boolean {
  return !!OPENAI_API_KEY && GPT5_ENABLED;
}

/**
 * Get all GPT-5 family tools
 */
export function getAllGPT5Tools() {
  if (!isGPT5Available()) {
    if (OPENAI_API_KEY && !GPT5_ENABLED) {
      console.log('GPT-5 tools disabled by feature flag. Using GPT-4.1 models instead.');
    }
    return [];
  }
  
  return [
    gpt5ReasonTool,
    gpt5MiniTool,
    gpt5NanoTool,
    compareGPT5vsGPT4Tool
  ];
}

/**
 * Get recommended GPT-5 model for task
 */
export function getRecommendedGPT5Model(
  complexity: "simple" | "moderate" | "complex",
  budgetSensitive: boolean = true
): { model: GPT5Model; requiresConfirmation: boolean } {
  if (complexity === "simple") {
    return { model: GPT5Model.GPT5_NANO, requiresConfirmation: false };
  }
  
  if (complexity === "complex" && !budgetSensitive) {
    return { model: GPT5Model.GPT5, requiresConfirmation: true };
  }
  
  // Default to GPT-5-mini for most cases
  return { model: GPT5Model.GPT5_MINI, requiresConfirmation: false };
}