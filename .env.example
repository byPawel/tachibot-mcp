# TachiBot MCP v2.0 - Configuration
# Copy this file to .env and add your API keys

# ===================================
# Profile Selection
# ===================================
# Choose your tool profile (controls which tools are loaded)
# Options: minimal, research_power, code_focus, balanced, full
# Default: balanced (if not specified)
# See TOOL_PROFILES.md for details
TACHIBOT_PROFILE=balanced

# ===================================
# Output Rendering
# ===================================
# How tool outputs should be rendered
# Options:
#   markdown - Raw markdown, no processing (default, ~1x tokens)
#   ink      - React Ink with themes, gradients, tables (~12x tokens)
#   ansi     - Legacy marked-terminal rendering
#   plain    - Stripped plain text
RENDER_OUTPUT=markdown

# Terminal theme for ANSI output
# Options:
#   nebula   - Modern SaaS look, soft pastels (default)
#   cyberpunk - High contrast neon, Blade Runner vibes
#   minimal  - Swiss typography, mostly monochrome
#   ocean    - Cool blues and teals, calm professional
TACHIBOT_THEME=nebula

# ===================================
# Required API Keys
# ===================================
# Get your API keys from:
# - Perplexity: https://www.perplexity.ai/settings/api
# - Grok/xAI: https://console.x.ai/
# - OpenAI: https://platform.openai.com/api-keys
# - Google Gemini: https://aistudio.google.com/apikey

# Perplexity API (for web search, research, reasoning)
PERPLEXITY_API_KEY=

# Grok/xAI API (for code analysis, debugging, architecture)
# Get from: https://console.x.ai/
XAI_API_KEY=
# Legacy alias (both work):
# GROK_API_KEY=

# OpenAI API (for GPT-5, analysis, comparison)
OPENAI_API_KEY=

# ===================================
# Optional API Keys
# ===================================
# Google Gemini API (for brainstorming, code/text analysis)
GOOGLE_API_KEY=

# OpenRouter API (for Qwen3 Coder, Kimi, and gateway mode)
OPENROUTER_API_KEY=

# ===================================
# OpenRouter Gateway Mode (Optional)
# ===================================
# When enabled, routes OpenAI/Gemini/Grok through OpenRouter
# Benefits: Single API key, unified billing, automatic fallbacks
# Note: Kimi/Qwen always use OpenRouter, Perplexity always uses direct API
USE_OPENROUTER_GATEWAY=false

# Anthropic API (optional - not currently used in Claude Code mode)
# ANTHROPIC_API_KEY=

# Qwen API (for Qwen Max model)
QWEN_API_KEY=

# ===================================
# Memory System (Optional)
# ===================================
# Supabase configuration for persistent memory storage
SUPABASE_URL=
SUPABASE_SERVICE_KEY=

# ===================================
# Performance Settings
# ===================================
# Note: TachiBot does not track API costs internally
# Monitor your usage through each provider's dashboard

# ===================================
# Timeout Configuration
# ===================================
# IMPORTANT: Adjust these if you experience timeout errors
# Multi-model operations (verifier, challenger) can take 60-180s
# Complex workflows can take 5-10 minutes

# Global default timeout for all operations (milliseconds)
# Default: 90000 (90 seconds)
TACHI_DEFAULT_TIMEOUT=90000

# Per-tool timeout overrides (milliseconds)
# Verifier: Multi-model parallel verification (default: 120000 = 2 min)
TACHI_VERIFIER_TIMEOUT=120000

# Challenger: Critical analysis with fact-checking (default: 180000 = 3 min)
TACHI_CHALLENGER_TIMEOUT=180000

# Scout: Information gathering with live search (default: 180000 = 3 min)
TACHI_SCOUT_TIMEOUT=180000

# Focus: Deep reasoning and collaborative sessions (default: 300000 = 5 min)
TACHI_FOCUS_TIMEOUT=300000

# Workflow: Complex multi-step workflows (default: 300000 = 5 min)
TACHI_WORKFLOW_TIMEOUT=300000

# PingPong: Multi-round conversations (default: 600000 = 10 min)
TACHI_PINGPONG_TIMEOUT=600000

# Individual API call timeout (default: 60000 = 1 min)
# This is PER API call, not total operation time
TACHI_API_TIMEOUT=60000

# Show progress for operations exceeding this duration (default: 30000 = 30s)
TACHI_PROGRESS_THRESHOLD=30000

# ===================================
# Workflow Configuration
# ===================================
# Max ping-pong brainstorm rounds (default: 24)
# Higher values = deeper reasoning but more cost
MAX_PINGPONG_ROUNDS=24

# Max reasoning rounds for collaborative sessions (1-10)
MAX_REASONING_ROUNDS=5

# ===================================
# Search & Research Configuration
# ===================================
# Default search provider for scout/research (perplexity, grok, both)
DEFAULT_SEARCH_PROVIDER=perplexity

# Enable Grok-4 live search in scout mode (costs extra per 1k sources)
ENABLE_GROK_LIVE_SEARCH=false

# Max sources for Grok live search (default: 100, lower = cheaper)
GROK_SEARCH_SOURCES_LIMIT=100

# ===================================
# Optional Settings
# ===================================
# Enable visual ASCII art in output
ENABLE_VISUALS=true

# Enable debug logging
DEBUG=false

# Default technical domain for brainstorming
# Options: architecture, algorithms, debugging, security,
#          performance, api_design, database, frontend,
#          backend, devops, testing
DEFAULT_DOMAIN=

# ============================================================================
# OUTPUT DIRECTORY CONFIGURATION
# ============================================================================
# All workflow and session outputs go to workflow-output/ by default
# Override these to customize output locations

# Base directory for all workflow outputs (workflows/*.yaml execution results)
# Default: ./workflow-output
# WORKFLOW_OUTPUT_DIR=./workflow-output

# Directory for session logs (focus/pingpong tool outputs)
# Default: ./workflow-output/sessions
# SESSION_OUTPUT_DIR=./workflow-output/sessions

# ============================================================================
# SESSION CONFIGURATION
# ============================================================================
# Controls session logging behavior for focus and pingpong tools

# Enable session logging (saves markdown/json/html logs)
# Default: true
# ENABLE_SESSION_LOGGING=true

# Automatically save sessions after completion
# Default: false
# SESSION_AUTO_SAVE=false

# Show verbose output during session execution
# Default: false
# SESSION_DEFAULT_VERBOSE=false

# Output format for session logs
# Options: markdown, json, html
# Default: markdown
# SESSION_DEFAULT_FORMAT=markdown

# Include metadata (tokens, timing, models) in session logs
# Default: true
# SESSION_INCLUDE_METADATA=true

# Maximum number of session history entries to keep
# Default: 100
# SESSION_MAX_HISTORY=100

# ===================================
# Local Model Configuration (Optional)
# ===================================
# Configure local model endpoints if you run your own models

# LMStudio endpoint
LMSTUDIO_BASE_URL=

# Ollama endpoint
OLLAMA_BASE_URL=

# ===================================
# Advanced: Model-Specific Overrides
# ===================================
# Only change these if you need fine-grained control

# Enable GPT-5 models (requires OpenAI API key)
ENABLE_GPT5=false

# Enable competitive Qwen mode (enables multi-model parallel reasoning)
ENABLE_QWEN_COMPETITIVE=false

# Enable expensive models (currently only grok_heavy - 256k context)
ENABLE_EXPENSIVE_MODELS=false

# Grok Configuration
ENABLE_GROK_HEAVY=false
GROK_MAX_TOKENS=100000
GROK_COST_LIMIT=1.0

# Model priority (lower = higher priority)
GROK_PRIORITY=2

# ===================================
# Advanced: Tool-Specific Overrides
# ===================================
# Force enable/disable specific tools regardless of profile
# Example: ENABLE_TOOL_PINGPONG=true
# Example: DISABLE_TOOL_GROK_SEARCH=false

# ===================================
# Model Selection (Multi-Model Tools)
# ===================================
# Configure which models are used for Scout, Challenger, and Verifier
# These tools run multiple models in parallel for consensus/verification
# Comma-separated list of model names (no spaces)

# Scout model configuration
# quick_scout: Fast checks, cost-efficient (default: qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini)
SCOUT_QUICK_MODELS=qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini

# research_scout: Thorough research (default: qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini)
SCOUT_RESEARCH_MODELS=qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini

# Challenger model configuration
# Used for critical analysis and counter-arguments (default: qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini)
CHALLENGER_MODELS=qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini

# Verifier model configuration
# quick_verify: Fast verification (default: qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini)
VERIFIER_QUICK_MODELS=qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini

# standard modes (fact_check, code_verify, security_verify): Balance quality & cost (default: qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini)
VERIFIER_STANDARD_MODELS=qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini

# deep_verify: Maximum quality for critical verification (default: qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5)
VERIFIER_DEEP_MODELS=qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5

# Default models for fallback (default: qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini)
DEFAULT_MODELS=qwen/qwen3-coder-plus,gemini-3-pro-preview,gpt-5-mini

# ===================================
# Model Selection Tips
# ===================================
# gpt-5-mini vs gpt-5:
# - gpt-5-mini: Faster, good for most tasks
# - gpt-5: Full quality, best for critical decisions
#
# gemini-3-pro-preview vs gemini-3-pro-preview:
# - flash: Faster, good for quick checks
# - pro: Better reasoning, accuracy, recommended for verification tasks
#
# Recommendation: Use defaults (gpt-5-mini + flash) for speed and lower costs.
